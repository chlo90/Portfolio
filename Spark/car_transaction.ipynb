{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "event_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferSchema='true').load('/FileStore/tables/dataSetEvents.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "split_col = split(event_df['timestamp'], ' ')\n",
    "df = event_df.withColumn('Date', split_col.getItem(0))\n",
    "df = event_df.withColumn('Time', split_col.getItem(1))\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "def event_split(x):\n",
    "  y=copy.deepcopy(x).asDict()\n",
    "  event=y['event'].replace(\"_\",\" \").split()\n",
    "  y['event_action'] = event[0]\n",
    "  target_string = event[1:len(event)]\n",
    "  y['event_target'] = (\" \".join(str(x) for x in target_string))\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_details = df.select(\"event\").rdd.map(event_split).toDF().distinct()\n",
    "display(event_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.join(event_details, on='event', how='inner').distinct()\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Prof. Franke \n",
    "from pyspark.sql import Row\n",
    "def mapRow1(aRow):\n",
    "  newRow = aRow.asDict()\n",
    "  newRow['event'] = aRow['event'].split()[0]\n",
    "  return Row(**newRow)\n",
    "\n",
    "def mapRow29(aRow):\n",
    "  newRow = Row(vin = aRow['vin'], event = aRow['event']).split()[0], count = aRow['count']\n",
    "  return newRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapRow1(display(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col_2 = pyspark.sql.functions.split(df_2['timestamp'], ' ')\n",
    "df_2 = df_2.withColumn('Date', split_col_2.getItem(0))\n",
    "df_2 = df_2.withColumn('Time', split_col_2.getItem(1))\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "from pyspark.sql.functions import lit \n",
    "\n",
    "df_2 = df_2.withColumn('vin_prefix', concat(df_2.vin.substr(1,8), lit('_'), df_2.vin.substr(10,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "YMM = df_2.select('vin_prefix', 'year', 'make', 'model').distinct().orderBy('make','model','year','vin_prefix')\n",
    "display(YMM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "YMM.repartition(1).write.format(\"com.databricks.spark.csv\").options(header=\"true\").save(\"/mnt/%s/Output/Spark-HW4/try8\" %MOUNT_NAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIN = df_2.select('vin', 'vin_prefix', 'trim', 'body_style', 'cab_style').distinct().orderBy('vin')\n",
    "display(VIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIN.repartition(1).write.format(\"com.databricks.spark.csv\").options(header=\"true\").save(\"/mnt/%s/Output/Spark-HW4/try9\" %MOUNT_NAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = df.select('zip', 'city', 'state').distinct().orderBy('zip', 'city', 'state')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.repartition(1).write.format(\"com.databricks.spark.csv\").options(header=\"true\").save(\"/mnt/%s/Output/Spark-HW4/try10\" %MOUNT_NAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumption: location = zip \n",
    "listing = df_2.select('vin', 'Date', 'zip','condition', 'price', 'mileage', 'image_count').distinct().orderBy('vin', 'Date')\n",
    "display(listing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing.repartition(1).write.format(\"com.databricks.spark.csv\").options(header=\"true\").save(\"/mnt/%s/Output/Spark-HW4/try11\" %MOUNT_NAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = df_2.select('user_id', 'vin', 'Date', 'referring_domain', 'event_action', 'event_target').groupBy('user_id', 'vin', 'Date', 'referring_domain', 'event_action', 'event_target').count().orderBy('user_id', 'vin', 'Date', 'referring_domain', 'event_action', 'event_target')\n",
    "display(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.repartition(1).write.format(\"com.databricks.spark.csv\").options(header=\"true\").save(\"/mnt/%s/Output/Spark-HW4/try13\" %MOUNT_NAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising_df = df_2.join(event, on=[df_2.user_id==event.user_id], how='inner').drop(event.user_id).drop(event.vin).drop(event.referring_domain)\n",
    "display(advertising_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising_count = advertising_df.groupBy('user_id', 'vin').count().orderBy('user_id')\n",
    "display(advertising_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print advertising_count.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "advDF2= df_2.select('user_id', 'vin', 'condition', 'price', 'mileage', 'year').distinct()\n",
    "advDF2=advDF2.join(advertising_count, on=[advDF2.user_id==advertising_count.user_id, advDF2.vin==advertising_count.vin], how='inner').drop(advertising_count.user_id).drop(advertising_count.vin)\n",
    "display(advDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "print advDF2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "advDF2.repartition(1).write.format(\"com.databricks.spark.csv\").options(header=\"true\").save(\"/mnt/%s/Output/Spark-HW4/try12\" %MOUNT_NAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_listing = advertising_count.join(listing, on=[advertising_count.vin == listing.vin], how='inner').drop(listing.image_count).drop(listing.vin)\n",
    "joined_listing.count()\n",
    "joined_vin = joined_listing.join(VIN, on = [joined_listing.vin==VIN.vin], how='inner').drop(joined_listing.vin).drop(VIN.body_style).drop(VIN.cab_style).drop(VIN.trim)\n",
    "display(joined_vin)\n",
    "joined_ymm = joined_vin.join(YMM, on=[YMM.vin_prefix == joined_vin.vin_prefix], how='inner')\n",
    "\n",
    "print joined_ymm.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "HW 4",
  "notebookId": 366260344081240
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
